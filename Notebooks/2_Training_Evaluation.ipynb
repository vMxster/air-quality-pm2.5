{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvVxxvpq2pGF"
      },
      "source": [
        "# Previsione della Qualità dell'Aria - **Allenamento e Valutazione dei Modelli**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm3Q39LW2Z4t"
      },
      "source": [
        "**Progetto di Data Intensive**  \n",
        "**Autore:** Martin Tomassi, Jacopo Vasi  \n",
        "**Email:** martin.tomassi@studio.unibo.it , jacopo.vasi@studio.unibo.it  \n",
        "**Corso:** Data Intensive, Università di Bologna  \n",
        "**Data:** Aprile 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnXzcSTc2Z4u"
      },
      "source": [
        "## Caricamento dei Datasets ed Import Librerie\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts2wiQjcg4BV"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "from urllib.request import urlretrieve\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import glob\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "%pip install tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    running_in_colab = True\n",
        "except ImportError:\n",
        "    running_in_colab = False\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import (\n",
        "    r2_score,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    mean_absolute_percentage_error,\n",
        "    mean_squared_log_error,\n",
        "    explained_variance_score,\n",
        "    max_error\n",
        ")\n",
        "from sklearn.model_selection import (\n",
        "    TimeSeriesSplit,\n",
        "    RandomizedSearchCV,\n",
        "    GridSearchCV,\n",
        "    ParameterSampler\n",
        ")\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression,\n",
        "    Lasso,\n",
        "    Ridge,\n",
        "    ElasticNet\n",
        ")\n",
        "\n",
        "import xgboost as xgb\n",
        "from IPython.display import clear_output\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "\n",
        "%pip install xgboost\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "N_JOBS = -1\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/vMxster/Data_Project/main/Datasets/original_dataset.csv',\n",
        "                 sep=',',\n",
        "                 quotechar='\"',\n",
        "                 dtype=None,\n",
        "                 parse_dates=True,\n",
        "                 low_memory=False)\n",
        "obj_cols = df.select_dtypes(include=\"object\").columns\n",
        "for col in obj_cols:\n",
        "    df[col] = df[col].astype(\"string\")\n",
        "df.drop('date', axis=1, inplace=True)\n",
        "df = df[(df['year'] >= 2019) & (df['year'] <= 2022)]\n",
        "df = df.reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "B-1nc39QrJSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "j5J-7bPorgC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcIEc735lViq",
        "tags": []
      },
      "source": [
        "# Addestramento modelli\n",
        "A seguito dell'esplorazione e dell'omogeneizzazione dei due dataset, si può procedere all'addestramento dei modelli. I modelli verranno addestrati sulle seguenti feature indipendenti:\n",
        "- `year`: anno della misurazione\n",
        "- `month`: mese dell’anno\n",
        "- `dayofmonth`: giorno del mese\n",
        "- `dayofweek`: giorno della settimana\n",
        "- `dayofyear`: giorno dell’anno\n",
        "- `weekofyear`: settimana dell’anno\n",
        "- `quarter`: trimestre dell’anno\n",
        "- `state`: stato di misurazione\n",
        "- `pm_lag_1W`: PM2.5 ritardato di 1 settimana\n",
        "- `pm_lag_1M`: PM2.5 ritardato di 1 mese\n",
        "- `pm_lag_1Y`: PM2.5 ritardato di 1 anno\n",
        "- `pm_lag_2Y`: PM2.5 ritardato di 2 anni\n",
        "- `co_lag_1W`: CO ritardato di 1 settimana\n",
        "- `co_lag_1M`: CO ritardato di 1 mese\n",
        "- `co_lag_1Y`: CO ritardato di 1 anno\n",
        "- `co_lag_2Y`: CO ritardato di 2 anni\n",
        "- `o3_lag_1W`: O3 ritardato di 1 settimana\n",
        "- `o3_lag_1M`: O3 ritardato di 1 mese\n",
        "- `o3_lag_1Y`: O3 ritardato di 1 anno\n",
        "- `o3_lag_2Y`: O3 ritardato di 2 anni"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwC-dywTlViq"
      },
      "source": [
        "La variabile dipendente target dell'addestramento è `PM2.5`, che indica la concentrazione di particelle inquinanti nell'aria con un diametro inferiore a 2,5 micron (μm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GveBLWbLlViq"
      },
      "source": [
        "## Preparazione Dataset\n",
        "Per garantire un confronto equo tra tutti i modelli, alcuni dei quali non supportano i valori mancanti generati dalle lag features, elimineremo tutte le righe che li contengono. Va però tenuto presente che così facendo perdiamo un anno di dati storici. Modelli come XGBoost di scikit-learn sono in grado di gestire internamente i missing value e potrebbero beneficiarne; tuttavia, per mantenere omogenee le condizioni di allenamento, applichiamo il drop completo dei NaN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u4WO1bmlViq"
      },
      "outputs": [],
      "source": [
        "target = 'PM2.5'\n",
        "lag_features = ['pm_lag_1Y', 'pm_lag_2Y', 'pm_lag_1M', 'pm_lag_1W','co_lag_1Y', 'co_lag_2Y', 'co_lag_1M', 'co_lag_1W','o3_lag_1Y', 'o3_lag_2Y', 'o3_lag_1M', 'o3_lag_1W']\n",
        "date_features = ['dayofmonth', 'dayofweek', 'dayofyear', 'weekofyear', 'month', 'quarter', 'year', 'state']\n",
        "predictors = date_features + lag_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efbb3yDvuaDc"
      },
      "outputs": [],
      "source": [
        "def create_train_test_sets(dataframe, split, replace_na=False, method='none'):\n",
        "    dataframe = dataframe.copy()\n",
        "\n",
        "    if replace_na and method == 'zeros':\n",
        "      dataframe = dataframe.fillna(0)\n",
        "    elif replace_na and method == 'drop':\n",
        "      dataframe = dataframe.dropna(how='any')\n",
        "\n",
        "    train_set, test_set = np.split(dataframe, [int(len(dataframe) * split)])\n",
        "    return train_set[predictors], test_set[predictors], train_set[target], test_set[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_dgAHmhuh2i"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = create_train_test_sets(\n",
        "    df,\n",
        "    split=0.8,\n",
        "    replace_na=True,\n",
        "    method='drop'\n",
        ")\n",
        "\n",
        "# Resetta gli indici dei risultati di create_train_test_sets eliminando l’indice precedente,\n",
        "# in modo da partire da zero e avere indici continui\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "\n",
        "X = pd.concat([X_train, X_test])\n",
        "y = pd.concat([y_train, y_test])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "3Mz9jup_67xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.info()"
      ],
      "metadata": {
        "id": "gl2OvBn56_PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqBCT7crrf9A"
      },
      "source": [
        "Nel dataset ci sono sia feature numeriche che categoriche. <br>\n",
        "Per le numeriche è necessario applicare una normalizzazione dei dati, i quali avrebbero altrimenti valori su scale molto diverse che renderebbero più difficile la convergenza del modello. <br>\n",
        "Per poter utilizzare le variabili categoriche nell'addestramento di un modello di regressione si usa un OneHotEncoder, creando nuove colonne binarie per ciascuno dei valori ammissibili dalla variabile categorica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcK3Ma4545-a"
      },
      "outputs": [],
      "source": [
        "categorical_features = X.select_dtypes(include=[\"string\"]).columns.tolist()\n",
        "numerical_features   = [c for c in X.columns if c not in categorical_features]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    # Standardizza tutte le colonne numeriche\n",
        "    (\"numeric\",    StandardScaler(),    numerical_features),\n",
        "    # One‑hot encoding di 'state', ignorando nuovi stati in predict\n",
        "    (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axPc4fYaKiDT"
      },
      "source": [
        "Inizializzazione della lista per raccogliere le metriche dopo ogni training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LfV4nYJKiPx"
      },
      "outputs": [],
      "source": [
        "all_scores = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_bIhHTRKAzQ"
      },
      "source": [
        "## Valutazione delle Prestazioni dei Modelli Allenati\n",
        "\n",
        "Dopo l'allenamento di ciascun modello di Machine Learning e Deep Learning, utilizziamo la funzione `get_estimator_scores` e `get_torch_estimator_scores` per calcolare diverse metriche di valutazione, includendo per le principali anche gli **Intervalli di Confidenza al 95%** (CI95%) stimati tramite bootstrap resampling.\n",
        "\n",
        "Le metriche calcolate sono:\n",
        "\n",
        "1. **$R^2$ (Coefficiente di Determinazione)**  \n",
        "   Misura quanto bene un modello riesce a spiegare la variabilità della variabile dipendente. Il valore di $R^2$ varia da 0 (nessuna capacità predittiva) a 1 (predizione perfetta).  \n",
        "   Un $R^2_{\\text{test}}$ significativamente inferiore rispetto a $R^2_{\\text{train}}$ indica possibile overfitting.  \n",
        "   *(Più alto è, meglio è.)*\n",
        "\n",
        "2. **Root Mean Squared Error (RMSE)**  \n",
        "   Misura la deviazione standard degli errori di previsione (la radice quadrata del MSE). Penalizza maggiormente gli errori più grandi.  \n",
        "   *(Più basso è, meglio è.)*\n",
        "\n",
        "3. **Mean Absolute Error (MAE)**  \n",
        "   Rappresenta la media delle differenze assolute tra i valori reali e quelli predetti. È meno sensibile agli outlier rispetto all’RMSE.  \n",
        "   *(Più basso è, meglio è.)*\n",
        "\n",
        "4. **Mean Absolute Percentage Error (MAPE)**  \n",
        "   Misura la precisione percentuale di un sistema di previsione. Indica, in media, quanto si discosta una previsione rispetto al valore reale.  \n",
        "   *(Più basso è, meglio è.)*\n",
        "\n",
        "5. **Mean Squared Logarithmic Error (MSLE)**  \n",
        "   Utile quando si vuole penalizzare maggiormente gli errori relativi per valori piccoli e avere tolleranza su valori grandi.  \n",
        "   *(Più basso è, meglio è.)*\n",
        "\n",
        "6. **Explained Variance Score**  \n",
        "   Misura la proporzione della varianza spiegata dal modello, simile a $R^2$, ma può essere più informativo in caso di regressione non lineare.  \n",
        "   *(Più alto è, meglio è.)*\n",
        "\n",
        "7. **Max Error**  \n",
        "   Misura l’errore assoluto massimo commesso in una previsione.  \n",
        "   *(Più basso è, meglio è.)*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zthJQ-LRL-8J"
      },
      "outputs": [],
      "source": [
        "def bootstrap_ci(metric_fn, y_true, y_pred, n_bootstraps=1000, alpha=0.05):\n",
        "    y_true_arr = np.asarray(y_true)\n",
        "    y_pred_arr = np.asarray(y_pred)\n",
        "    vals = []\n",
        "    for _ in range(n_bootstraps):\n",
        "        if running_in_colab:\n",
        "            idx = np.random.randint(0, len(y_true), len(y_true))\n",
        "            vals.append(metric_fn(y_true[idx], y_pred[idx]))\n",
        "        else:\n",
        "            idx = np.random.randint(0, len(y_true), len(y_true))\n",
        "            vals.append(metric_fn(y_true_arr[idx], y_pred_arr[idx]))\n",
        "\n",
        "    low = np.percentile(vals, 100 * (alpha/2))\n",
        "    high = np.percentile(vals, 100 * (1 - alpha/2))\n",
        "    return low, high\n",
        "\n",
        "def get_estimator_scores(model_name, model):\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2_tr = model.score(X_train, y_train)\n",
        "    r2_te = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    msle = mean_squared_log_error(y_test, np.maximum(y_pred, 0))\n",
        "    evs = explained_variance_score(y_test, y_pred)\n",
        "    me = max_error(y_test, y_pred)\n",
        "\n",
        "    rmse_low, rmse_high = bootstrap_ci(lambda a,b: np.sqrt(mean_squared_error(a, b)), y_test, y_pred)\n",
        "    mae_low, mae_high = bootstrap_ci(mean_absolute_error, y_test, y_pred)\n",
        "    mape_low, mape_high = bootstrap_ci(mean_absolute_percentage_error, y_test, y_pred)\n",
        "\n",
        "    all_scores.append([\n",
        "        model_name, r2_tr, r2_te,\n",
        "        rmse, rmse_low, rmse_high,\n",
        "        mae, mae_low, mae_high,\n",
        "        mape, mape_low, mape_high,\n",
        "        msle, evs, me\n",
        "    ])\n",
        "\n",
        "def predict_torch(model, X_tensor, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(X_tensor.to(device))\n",
        "    out_cpu = out.detach().cpu().numpy()\n",
        "    # Se il modello restituisce shape (N,1), appiattiamo a (N,)\n",
        "    if out_cpu.ndim == 2 and out_cpu.shape[1] == 1:\n",
        "        return out_cpu.ravel()\n",
        "    return out_cpu\n",
        "\n",
        "def get_torch_estimator_scores(model_name, model,\n",
        "                               X_train, y_train,\n",
        "                               X_test, y_test,\n",
        "                               device):\n",
        "    y_pred_train = predict_torch(model, X_train, device)\n",
        "    y_pred_test  = predict_torch(model, X_test,  device)\n",
        "\n",
        "    y_train_np = y_train.detach().cpu().numpy().ravel()\n",
        "    y_test_np  = y_test.detach().cpu().numpy().ravel()\n",
        "\n",
        "    r2_tr = r2_score(y_train_np, y_pred_train)\n",
        "    r2_te = r2_score(y_test_np,  y_pred_test)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_np, y_pred_test))\n",
        "    rmse_low, rmse_high = bootstrap_ci(\n",
        "        lambda a, b: np.sqrt(mean_squared_error(a, b)),\n",
        "        y_test_np, y_pred_test\n",
        "    )\n",
        "\n",
        "    mae = mean_absolute_error(y_test_np, y_pred_test)\n",
        "    mae_low, mae_high = bootstrap_ci(mean_absolute_error, y_test_np, y_pred_test)\n",
        "    mape = mean_absolute_percentage_error(y_test_np, y_pred_test)\n",
        "    mape_low, mape_high = bootstrap_ci(mean_absolute_percentage_error,\n",
        "                                       y_test_np, y_pred_test)\n",
        "    msle = mean_squared_log_error(y_test_np, np.maximum(y_pred_test, 0))\n",
        "    evs = explained_variance_score(y_test_np, y_pred_test)\n",
        "    me = max_error(y_test_np, y_pred_test)\n",
        "\n",
        "    all_scores.append([\n",
        "        model_name, r2_tr, r2_te,\n",
        "        rmse, rmse_low, rmse_high,\n",
        "        mae, mae_low, mae_high,\n",
        "        mape, mape_low, mape_high,\n",
        "        msle, evs, me\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOMRnqcslVir"
      },
      "source": [
        "## Regressione lineare\n",
        "Il modello più semplice da addestrare è la regressione lineare, senza filtri polinomiali o regolarizzazioni. Grazie all'elevato numero di dati usato per l'addestramento, si possono ottenere degli ottimi risultati, anche se migliorabili, già con questo primo modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSsOPwFNlVir"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"regr\"   , LinearRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVduMAAHlVir"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)\n",
        "get_estimator_scores(\"lin_reg\", model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP2p8Z1ClVit",
        "tags": []
      },
      "source": [
        "## Regressione polinomiale\n",
        "Per provare ad ottenere risultati migliori, vengono introdotte le feature polinomiali, che aggiungono nuove feature di grado superiore. Si esclude il bias, che consiste nel valore dell'intercetta, e si escludono i prodotti tra le diverse feature, per esempio i doppi prodotti in una regressione polinomiale di grado 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n3i5NhmlVit"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),\n",
        "    (\"regr\"   , LinearRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txYsQh_mlViw"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)\n",
        "get_estimator_scores(\"poly_reg\", model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCa0HV05lVix",
        "tags": []
      },
      "source": [
        "## Regressione LASSO\n",
        "La regressione LASSO è un'ottima tecnica per selezionare le feature più importanti, poichè la discesa del gradiente si ferma su un vertice di un ipercubo centrato sull'origine, quindi azzera i parametri delle variabili meno rilevanti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO8UrLjylVix"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"regr\", Lasso(alpha=1, max_iter=10000))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW41o83llVix"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBNwKTBslViy"
      },
      "source": [
        "### Grid Search per l'iperparametro della Lasso\n",
        "Per ricercare gli iperparametri migliori nei prossimi modelli da addestrare, verrà usata la grid search o random search, che addestra il modello con tutte le combinazioni possibili di iperparametri selezionati. <br>\n",
        "All'interno della grid search, suddividiamo i dati in 5 sottoinsiemi disgiunti, i fold della cross validation, per garantire che il modello riesca a generalizzare su dati non visti. <br>\n",
        "Con la grid search si ottiene lo score del modello al variare dell'iperparametro della regolarizzazione LASSO per vedere quanta regolarizzazione è necessaria ai fini dell'addestramento."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tscv = TimeSeriesSplit(n_splits=5)"
      ],
      "metadata": {
        "id": "rAjFXQPQlX-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(tscv.n_splits, 1, figsize=(12, 12), sharex=True)\n",
        "fig.tight_layout(pad=3.0)\n",
        "\n",
        "for index, (train_fold, validation_fold) in enumerate(tscv.split(y_train)):\n",
        "    sns.lineplot(data=y_train.iloc[train_fold], label='Training Set', ax=axes[index])\n",
        "    sns.lineplot(data=y_train.iloc[validation_fold], label='Validation Set', ax=axes[index])\n",
        "    axes[index].set_title(f'Time Series Split #{index}')\n",
        "    axes[index].set(xlabel=None, ylabel=None)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H2V0j1jhk9yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkU3BKTAlViy"
      },
      "outputs": [],
      "source": [
        "alphas = np.logspace(-3, 1, num=5)\n",
        "grid = {\"regr__alpha\": alphas}\n",
        "gs = RandomizedSearchCV(model, grid, n_iter=5, cv=tscv, n_jobs=N_JOBS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyNpEms_lViz"
      },
      "outputs": [],
      "source": [
        "%time gs.fit(X_train, y_train);\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfRSNZkelViz"
      },
      "outputs": [],
      "source": [
        "get_estimator_scores(\"lasso_reg\", gs.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJebrS-JlViz"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(gs.cv_results_)[[\"param_regr__alpha\", \"mean_test_score\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZZdd025lViz"
      },
      "outputs": [],
      "source": [
        "plt.plot(results[\"param_regr__alpha\"], results[\"mean_test_score\"])\n",
        "plt.xscale('log')\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('score')\n",
        "plt.title('Grafico al variare della regolarizzazione')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcl2wO-FlVi0"
      },
      "source": [
        "## Regressione Ridge\n",
        "Proviamo la regolarizzazione con feature polinomiali per ridurre un eventuale overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUItTWw3lVi0"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"poly\",   PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),\n",
        "    (\"regr\", Ridge(alpha=1, max_iter=10000))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mqZrg_UlVi0"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CqjLtbdlVi0"
      },
      "source": [
        "### Grid Search per l'iperparametro della Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgQaK1ijlVi2"
      },
      "outputs": [],
      "source": [
        "alphas = np.logspace(-2, 8, num=12)\n",
        "grid = {\"regr__alpha\": alphas}\n",
        "gs = RandomizedSearchCV(model, grid, n_iter=12, cv=tscv, n_jobs=N_JOBS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvC3I0kzlVi2"
      },
      "outputs": [],
      "source": [
        "%time gs.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nqLv4gglVi2"
      },
      "outputs": [],
      "source": [
        "get_estimator_scores(\"ridge_reg\", gs.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJEkBHpTlVi2"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(gs.cv_results_)[[\"param_regr__alpha\", \"mean_test_score\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdyidkgYlVi3"
      },
      "outputs": [],
      "source": [
        "plt.plot(results[\"param_regr__alpha\"], results[\"mean_test_score\"])\n",
        "plt.xscale('log')\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('score')\n",
        "plt.title('Grafico al variare della regolarizzazione')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXwTWsC2lVi3"
      },
      "source": [
        "## Regressione Elastic Net\n",
        "Questa regressione unisce la regolarizzazione LASSO e la regolarizzazione Ridge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE5PXsuelVi3"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"poly\",   PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),\n",
        "    (\"regr\", ElasticNet(alpha=0.2, l1_ratio=0.1))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD_KhUiylVi3"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGubqzrxlVi3"
      },
      "source": [
        "### Grid Search per Elastic Net\n",
        "Nella grid search cerchiamo i valori migliori di `alpha`, iperparametro della regolarizzazione, e di `l1_ratio`, iperparametro per gestire l'unione di LASSO e Ridge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwcPfGK9lVi3"
      },
      "outputs": [],
      "source": [
        "grid = {\n",
        "    \"regr__alpha\":    [0.1, 1, 10],\n",
        "    \"regr__l1_ratio\": [0.1, 0.2, 0.3]\n",
        "}\n",
        "gs = RandomizedSearchCV(model, grid, n_iter=9, cv=tscv, n_jobs=N_JOBS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9qz_4YslVi3"
      },
      "outputs": [],
      "source": [
        "%time gs.fit(X_train, y_train);\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHfhGZSslVi4"
      },
      "outputs": [],
      "source": [
        "get_estimator_scores(\"elastic_net_reg\", gs.best_estimator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSqJT3J-lVi4",
        "tags": []
      },
      "source": [
        "## Regressione con funzioni kernel\n",
        "Per ovviare ai problemi di prestazioni dei modelli con feature polinomiali, usiamo il kernel trick per evitare di creare un numero elevato di feature aggiuntive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFj50pJolVi4",
        "tags": []
      },
      "source": [
        "## Funzioni kernel polinomiali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xa639FtlVi4"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"regr\",  KernelRidge(alpha=1, kernel=\"poly\", degree=10))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnFxvlfPlVi4"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOaI0YJZlVi4",
        "tags": []
      },
      "source": [
        "### Grid Search per funzioni kernel polinomiali\n",
        "Questa grid search cerca i valori ottimali del peso della regolarizzazione e del grado della funzione kernel polinomiale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffHhHFyllVi4"
      },
      "outputs": [],
      "source": [
        "grid = {\n",
        "    \"regr__alpha\":    [0.1, 1, 10],\n",
        "    \"regr__degree\": list(range(2,30))\n",
        "}\n",
        "gs = RandomizedSearchCV(model, grid, n_iter=20, cv=tscv, n_jobs=N_JOBS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scelta del numero di iterazioni per RandomizedSearchCV con questo grid**\n",
        "\n",
        "Il grid ha:\n",
        "\n",
        "- Configurazioni Totali:\n",
        "$$\n",
        "M = |\\text{max_depth}| \\times |\\text{min_samples_split}| = 28 \\times 4 = 84 $$\n",
        "\n",
        "Supponiamo di voler avere una probabilità \\(P = 0.90\\) di includere almeno una delle migliori \\(k = 10\\) configurazioni tra queste 84.\n",
        "\n",
        "Usiamo la formula:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
        "$$\n",
        "\n",
        "Calcoliamo l’approssimazione:\n",
        "\n",
        "$$\n",
        "n \\approx - \\frac{\\ln(1 - 0.90)}{10/104} = \\frac{2.3026}{10/84} = 2.3026 \\times \\frac{84}{10} \\approx 20\n",
        "$$\n",
        "\n",
        "Quindi, con **20 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando rispetto a un Grid Search completo con 84 tentativi.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NC1W0ztHymoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Da dove viene la formula per stimare il numero di iterazioni nel Randomized Search?**\n",
        "\n",
        "Per stimare quante iterazioni (`n`) sono necessarie per avere una certa probabilità \\(P\\) di includere almeno una configurazione tra le \\(k\\) migliori (su \\(M\\) totali), usiamo la seguente logica probabilistica:\n",
        "\n",
        "1. Probabilità di *non* pescare una top-\\(k\\) in un singolo tentativo.\n",
        "Se ci sono \\(M\\) configurazioni totali e \\(k\\) di esse sono “quasi ottimali”, la probabilità di *non* sceglierne una buona è:\n",
        "$$\n",
        "1 - \\frac{k}{M}\n",
        "$$\n",
        "\n",
        "2. Probabilità di non pescarne *nessuna* in \\(n\\) tentativi indipendenti\n",
        "$$\n",
        "\\left(1 - \\frac{k}{M} \\right)^n\n",
        "$$\n",
        "\n",
        "3. Probabilità di pescare **almeno una** delle top-\\(k\\)\n",
        "$$\n",
        "P(\\text{≥1 top-}k) = 1 - \\left(1 - \\frac{k}{M} \\right)^n\n",
        "$$\n",
        "\n",
        "4. Ricavare \\(n\\) dalla formula\n",
        "$$\n",
        "1 - \\left(1 - \\frac{k}{M} \\right)^n = P\n",
        "\\quad \\Longrightarrow \\quad\n",
        "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M} \\right)}\n",
        "$$\n",
        "\n",
        "5. Approssimazione per $$ k \\ll M $$\n",
        "Poiché $$ \\ln(1 - x) \\approx -x $$ per \\(x\\) piccolo:\n",
        "$$\n",
        "n \\approx - \\frac{\\ln(1 - P)}{k/M}\n",
        "$$"
      ],
      "metadata": {
        "id": "Wrc2Kg0DyqcO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UBMc_JPlVi5"
      },
      "outputs": [],
      "source": [
        "%time gs.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsrbR4InlVi5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "get_estimator_scores(\"kernel_poly_reg\", gs.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShgWWvDBlVi5"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(gs.cv_results_)[[\"param_regr__alpha\",\"param_regr__degree\",\"mean_test_score\"]]\n",
        "results_0_1 = results[results[\"param_regr__alpha\"] == 0.1]\n",
        "results_1 = results[results[\"param_regr__alpha\"] == 1]\n",
        "results_10 = results[results[\"param_regr__alpha\"] == 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0K5FibrlVi5"
      },
      "outputs": [],
      "source": [
        "plt.plot(results_0_1[\"param_regr__degree\"], results_0_1[\"mean_test_score\"])\n",
        "plt.plot(results_1[\"param_regr__degree\"], results_1[\"mean_test_score\"], c=\"red\")\n",
        "plt.plot(results_10[\"param_regr__degree\"], results_10[\"mean_test_score\"], c=\"green\")\n",
        "plt.xlabel('degree')\n",
        "plt.ylabel('score')\n",
        "plt.legend([\"alpha=0.1\",\"alpha=1\",\"alpha=10\"])\n",
        "plt.title('Grafico al variare del grado della funzione kernel polinomiale')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4RNo3BclVi5"
      },
      "source": [
        "## Funzioni kernel gaussiane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-78ywm3XlVi5"
      },
      "source": [
        "Testiamo anche funzioni kernel diverse, ad esempio RBF (_radial basis function_). <br>\n",
        "La funzione RBF ha la forma di una gaussiana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T5BL022lVi5"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"regr\",  KernelRidge(alpha=1, kernel=\"rbf\", gamma=0.01))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlJ8BI7UlVi6"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcj4BGSPlVi6"
      },
      "source": [
        "### Grid Search per funzioni kernel gaussiane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4S7RFNUlVi6"
      },
      "outputs": [],
      "source": [
        "grid = {\n",
        "    \"regr__alpha\":    [0.1, 1, 10],\n",
        "    \"regr__gamma\": [0.01, 0.1, 1]\n",
        "}\n",
        "gs = RandomizedSearchCV(model, grid, n_iter=9, cv=tscv, n_jobs=N_JOBS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBK7V6RvlVi6"
      },
      "outputs": [],
      "source": [
        "%time gs.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNj-dvsjlVi6"
      },
      "outputs": [],
      "source": [
        "get_estimator_scores(\"kernel_rbf_reg\", gs.best_estimator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sELWDyRclVi6"
      },
      "source": [
        "## Alberi decisionali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVoeA9SklVi6"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"tree\", DecisionTreeRegressor(max_depth=4, random_state=42))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOZPvS-MlVi7"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfO7GcablVi7"
      },
      "source": [
        "### Grid Search per alberi decisionali\n",
        "Cerchiamo i valori ottimali della profondità massima dell'albero decisionale e del numero minimo di campioni all'interno di ciascun nodo per poter essere suddiviso a sua volta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4wR3nZolVi7"
      },
      "outputs": [],
      "source": [
        "grid = {\n",
        "    \"tree__max_depth\": list(range(4,30)),\n",
        "    \"tree__min_samples_split\": [0.005, 0.01, 0.1, 0.15],\n",
        "}\n",
        "gs = RandomizedSearchCV(model, grid, n_iter=24, cv=tscv, n_jobs=N_JOBS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scelta del numero di iterazioni per RandomizedSearchCV con questo grid**\n",
        "\n",
        "Il grid ha:\n",
        "\n",
        "- Configurazioni Totali: $$ M = |\\text{max_depth}| \\times |\\text{min_samples_split}| = 26 \\times 4 = 104 $$\n",
        "\n",
        "Supponiamo di voler avere una probabilità \\(P = 0.90\\) di includere almeno una delle migliori \\(k = 10\\) configurazioni tra queste 104.\n",
        "\n",
        "Usiamo la formula:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
        "$$\n",
        "\n",
        "Calcoliamo l’approssimazione:\n",
        "\n",
        "$$\n",
        "n \\approx - \\frac{\\ln(1 - 0.90)}{10/104} = \\frac{2.3026}{10/104} = 2.3026 \\times \\frac{104}{10} \\approx 24\n",
        "$$\n",
        "\n",
        "Quindi, con **24 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando rispetto a un Grid Search completo con 104 tentativi.\n",
        "\n"
      ],
      "metadata": {
        "id": "dN2PpsCAy6Qw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My063uZrlVi7"
      },
      "outputs": [],
      "source": [
        "%time gs.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3w8NnP3lVi7"
      },
      "outputs": [],
      "source": [
        "get_estimator_scores(\"decision_tree_reg\", gs.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QK0x8yelVi7"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(gs.cv_results_)[[\n",
        "    \"param_tree__min_samples_split\",\n",
        "    \"param_tree__max_depth\",\n",
        "    \"mean_test_score\"\n",
        "]]\n",
        "splits = sorted(results[\"param_tree__min_samples_split\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma3qnu6clVi8"
      },
      "outputs": [],
      "source": [
        "for split in splits:\n",
        "    subset = results[results[\"param_tree__min_samples_split\"] == split]\n",
        "    subset = subset.sort_values(\"param_tree__max_depth\")\n",
        "    plt.plot(\n",
        "        subset[\"param_tree__max_depth\"],\n",
        "        subset[\"mean_test_score\"],\n",
        "        label=f\"min_samples_split={split}\"\n",
        "    )\n",
        "\n",
        "plt.xlabel('depth')\n",
        "plt.ylabel('score')\n",
        "plt.title(\"Performance al variare della Profonditá\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM7vW1UglVi8"
      },
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eieu-i1lVi9"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"tree\", RandomForestRegressor(max_samples=0.2, max_features=\"sqrt\", n_estimators=200, max_depth=None, n_jobs=-1))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB_F1HTDlVi9"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx9HoQcolVi9"
      },
      "source": [
        "Possiamo ricavare le 10 feature più importanti per la Random Forest, ovvero le variabili che sono state più utilizzate nella creazione degli alberi decisionali."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQVy9ajGlVi9"
      },
      "outputs": [],
      "source": [
        "pd.Series(model.named_steps[\"tree\"].feature_importances_, preprocessor.get_feature_names_out(X_train.columns)).sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY3JUaW7lVi9"
      },
      "source": [
        "### Grid Search per random forest\n",
        "Nella grid search cerchiamo i valori ottimali di `max_samples`, il numero massimo di campioni usati nell'addestramento di ciascun albero, e di `n_estimators`, il numero di alberi decisionali della foresta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S22MF1LolVi-"
      },
      "outputs": [],
      "source": [
        "grid = {\n",
        "    \"tree__n_estimators\": [150, 200, 250, 300],\n",
        "    \"tree__max_samples\": [0.5, 0.6, 0.8, 1.0],\n",
        "}\n",
        "gs = RandomizedSearchCV(model, grid, n_iter=16, cv=tscv, n_jobs=N_JOBS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqxUYeNElVi-"
      },
      "outputs": [],
      "source": [
        "%time gs.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML7A1bPflVi-"
      },
      "outputs": [],
      "source": [
        "get_estimator_scores(\"random_forest_reg\", gs.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srMzWDr1lVi-"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(gs.cv_results_)[[\"param_tree__n_estimators\",\"param_tree__max_samples\",\"mean_test_score\"]]\n",
        "results_0_5 = results[results[\"param_tree__max_samples\"] == 0.5]\n",
        "results_0_6 = results[results[\"param_tree__max_samples\"] == 0.6]\n",
        "results_0_8 = results[results[\"param_tree__max_samples\"] == 0.8]\n",
        "results_1 = results[results[\"param_tree__max_samples\"] == 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO-ajTvZlVi-"
      },
      "outputs": [],
      "source": [
        "plt.plot(results_0_5[\"param_tree__n_estimators\"], results_0_5[\"mean_test_score\"])\n",
        "plt.plot(results_0_6[\"param_tree__n_estimators\"], results_0_6[\"mean_test_score\"], c=\"red\")\n",
        "plt.plot(results_0_8[\"param_tree__n_estimators\"], results_0_8[\"mean_test_score\"], c=\"green\")\n",
        "plt.plot(results_1[\"param_tree__n_estimators\"], results_1[\"mean_test_score\"], c=\"gold\")\n",
        "plt.xlabel('n trees')\n",
        "plt.ylabel('score')\n",
        "plt.legend([\"max_samples=0.5\",\"max_samples=0.6\",\"max_samples=0.8\",\"max_samples=1\"])\n",
        "plt.title('Grafico al variare del numero di alberi del random forest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xPxYN70lVi_"
      },
      "source": [
        "## XGBoost\n",
        "XGBoost crea una foresta di alberi in cui ogni albero utilizza gli errori commessi dall'albero precedente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A4je0oplVjA"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"preproc\", preprocessor),\n",
        "    (\"xgb\", XGBRegressor(objective='reg:squarederror', n_estimators=200))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A3332KolVjA"
      },
      "outputs": [],
      "source": [
        "%time model.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUxDT_-nlVjA"
      },
      "source": [
        "Possiamo ricavare le 5 feature più importanti per XGBoost, ovvero le variabili che sono state più utilizzate nella creazione degli alberi decisionali."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us6Z4OmqlVjA"
      },
      "outputs": [],
      "source": [
        "pd.Series(model.named_steps[\"xgb\"].feature_importances_, preprocessor.get_feature_names_out(X_train.columns)).sort_values(ascending=False).head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uapeT7xKlVjA"
      },
      "source": [
        "### Grid Search per XGBoost\n",
        "Cerchiamo i valori ottimali di due iperparametri: la profondità massima degli alberi e il numero di alberi della foresta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwAwlSAxlVjA"
      },
      "outputs": [],
      "source": [
        "grid = {\n",
        "    \"xgb__max_depth\": [3, 5, 7, 10],\n",
        "    \"xgb__n_estimators\": [100, 200, 400, 700, 1000],\n",
        "}\n",
        "gs = RandomizedSearchCV(model, grid, n_iter=20, cv=tscv, n_jobs=N_JOBS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRafW1bilVjA"
      },
      "outputs": [],
      "source": [
        "%time gs.fit(X_train, y_train)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECO1JyGKlVjB"
      },
      "outputs": [],
      "source": [
        "get_estimator_scores(\"xgboost_reg\", gs.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uK3_8j4lVjB"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(gs.cv_results_)[[\"param_xgb__max_depth\",\"param_xgb__n_estimators\",\"mean_test_score\"]]\n",
        "results_3 = results[results[\"param_xgb__max_depth\"] == 3]\n",
        "results_5 = results[results[\"param_xgb__max_depth\"] == 5]\n",
        "results_7 = results[results[\"param_xgb__max_depth\"] == 7]\n",
        "results_10 = results[results[\"param_xgb__max_depth\"] == 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD3ex6kOlVjB"
      },
      "outputs": [],
      "source": [
        "plt.plot(results_3[\"param_xgb__n_estimators\"], results_3[\"mean_test_score\"])\n",
        "plt.plot(results_5[\"param_xgb__n_estimators\"], results_5[\"mean_test_score\"], c=\"red\")\n",
        "plt.plot(results_7[\"param_xgb__n_estimators\"], results_7[\"mean_test_score\"], c=\"green\")\n",
        "plt.plot(results_10[\"param_xgb__n_estimators\"], results_10[\"mean_test_score\"], c=\"gold\")\n",
        "plt.xlabel('n trees')\n",
        "plt.ylabel('score')\n",
        "plt.legend([\"max_depth=3\",\"max_depth=5\",\"max_depth=7\",\"max_depth=10\"])\n",
        "plt.title('Grafico al variare del numero del numero di alberi di XGBoost')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP"
      ],
      "metadata": {
        "id": "xlwH7ptOzQwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device utilizzato: {device}\")\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_sizes, dropout):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        dim = input_dim\n",
        "        for hs in hidden_sizes:\n",
        "            layers.append(nn.Linear(dim, hs))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            dim = hs\n",
        "        layers.append(nn.Linear(dim, 1))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "FKVjVeNVzTPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Search con Early Stopping\n",
        "\n",
        "Questo blocco di codice implementa una procedura completa di **Random Search** per la selezione di iperparametri di modelli di regressione in PyTorch, integrando una strategia di **Early Stopping** per migliorare l'efficienza del training.\n",
        "\n",
        "* La classe `EarlyStopper` consente di interrompere l'addestramento anticipatamente se la loss di validazione non migliora per un numero di epoche definito (`patience`), riducendo il rischio di overfitting e velocizzando l'ottimizzazione.\n",
        "* Le funzioni `train_epoch` ed `eval_loss` gestiscono rispettivamente il training e la valutazione della loss media su un dataset.\n",
        "* La funzione principale `random_search` esegue una **Cross-Validation**, dove:\n",
        "  * Il ciclo valuta le prestazioni generali del modello su diversi split train/test."
      ],
      "metadata": {
        "id": "CcnVXcxkzVxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=3, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "\n",
        "    def early_stop(self, val_loss):\n",
        "        # Se la loss migliora (di almeno min_delta), resettiamo il counter\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            # Se la loss non migliora da 'patience' epoche, dobbiamo fermarci\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for Xb, yb in loader:\n",
        "        Xb, yb = Xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(Xb), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_loss(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            total_loss += criterion(model(Xb), yb).item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def random_search(model_builder, param_dist, dataset,\n",
        "                  n_iter=10, cv_folds=5,\n",
        "                  early_patience=5,\n",
        "                  early_min_delta=1e-4):\n",
        "    train_keys = ['lr', 'batch_size', 'max_epochs']\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_params, best_train_params = None, None\n",
        "    best_model = None\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=cv_folds)\n",
        "\n",
        "    print(\"Avvio Random Search con Time Series Cross Validation...\")\n",
        "\n",
        "    for param_id, params in enumerate(ParameterSampler(param_dist, n_iter=n_iter, random_state=RANDOM_STATE)):\n",
        "        print(f\"Testing parameter set {param_id+1}/{n_iter}\")\n",
        "\n",
        "        model_params = {k: v for k, v in params.items() if k not in train_keys}\n",
        "        train_params = {k: v for k, v in params.items() if k in train_keys}\n",
        "        val_losses = []\n",
        "\n",
        "        for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(range(len(dataset)))):\n",
        "            print(f\"  Fold {fold_idx+1}/{cv_folds}\")\n",
        "\n",
        "            sub_train = Subset(dataset, train_idx)\n",
        "            val_set = Subset(dataset, val_idx)\n",
        "            train_loader = DataLoader(sub_train, batch_size=train_params['batch_size'], shuffle=True)\n",
        "            val_loader = DataLoader(val_set, batch_size=train_params['batch_size'], shuffle=False)\n",
        "\n",
        "            model = model_builder(**model_params).to(device)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=train_params['lr'])\n",
        "            stopper = EarlyStopper(patience=early_patience, min_delta=early_min_delta)\n",
        "\n",
        "            for epoch in range(train_params['max_epochs']):\n",
        "                train_epoch(model, train_loader, optimizer, nn.MSELoss())\n",
        "                val_loss = eval_loss(model, val_loader, nn.MSELoss())\n",
        "\n",
        "                if epoch % 10 == 0:  # Print every 10 epochs\n",
        "                    print(f\"    Epoch {epoch}: val_loss = {val_loss:.6f}\")\n",
        "\n",
        "                if stopper.early_stop(val_loss):\n",
        "                    print(f\"    Early stopping at epoch {epoch}\")\n",
        "                    break\n",
        "\n",
        "            final_val_loss = eval_loss(model, val_loader, nn.MSELoss())\n",
        "            val_losses.append(final_val_loss)\n",
        "\n",
        "        mean_val = np.mean(val_losses)\n",
        "        print(f\"  Mean validation loss: {mean_val:.6f}\")\n",
        "\n",
        "        if mean_val < best_val_loss:\n",
        "            best_val_loss = mean_val\n",
        "            best_model_params = model_params\n",
        "            best_train_params = train_params\n",
        "            best_model = model\n",
        "            print(f\"  New best validation loss: {best_val_loss:.6f}\")\n",
        "\n",
        "    print(f\"\\nBest validation loss: {best_val_loss:.6f}\")\n",
        "    return best_model, best_model_params, best_train_params"
      ],
      "metadata": {
        "id": "Iumk8NyQzZco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Esecuzione del Random Search su MLP\n",
        "\n",
        "In questa sezione viene eseguita la **ricerca di iperparametri tramite Random Search** per **MLP (Multi-Layer Perceptron)**.\n",
        "\n",
        "#### Definizione degli spazi degli iperparametri:\n",
        "\n",
        "* `mlp_param_dist`: contiene combinazioni di dimensioni dei layer nascosti, tassi di dropout, learning rate, batch size e numero massimo di epoche per il training del modello MLP.\n"
      ],
      "metadata": {
        "id": "OVD5006Oza85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# (Training + Validation) Dataset\n",
        "full_dataset = TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "input_dim = X_tensor.shape[1]\n",
        "mlp_param_dist = {\n",
        "    'input_dim': [input_dim],\n",
        "    'hidden_sizes': [(32,32), (64,64), (128,)],\n",
        "    'dropout': [0.0, 0.2, 0.5],\n",
        "    'lr': [1e-3, 1e-4],\n",
        "    'batch_size': [32, 64],\n",
        "    'max_epochs': [50]\n",
        "}\n",
        "best_model, model_params, train_params = random_search(\n",
        "    lambda **p: MLP(**p), mlp_param_dist, full_dataset\n",
        ")\n",
        "\n",
        "X_train_tensor = torch.stack([full_dataset[i][0] for i in range(len(full_dataset))])\n",
        "y_train_tensor = torch.stack([full_dataset[i][1] for i in range(len(full_dataset))])\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "get_torch_estimator_scores(\"MLP\", best_model,\n",
        "                           X_train_tensor.to(device), y_train_tensor.to(device),\n",
        "                           X_test_tensor, y_test_tensor,\n",
        "                           device)"
      ],
      "metadata": {
        "id": "lHuw7xi2zemy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uIugxCaMC9R"
      },
      "source": [
        "# Confronto Visivo delle Prestazioni dei Modelli\n",
        "\n",
        "La funzione `plot_estimator_scores(scores)` consente di visualizzare in modo sintetico ed intuitivo le metriche di valutazione di tutti i modelli allenati. I grafici generati permettono un confronto diretto tra le prestazioni su diverse metriche chiave:\n",
        "\n",
        "- **R² Score**: confronta le prestazioni sul training set e sul test set per identificare possibili fenomeni di overfitting.\n",
        "- **RMSE (Root Mean Squared Error)**: evidenzia la variabilità degli errori di previsione, penalizzando fortemente gli outlier.\n",
        "- **MAE (Mean Absolute Error)**: mostra la media dell’errore assoluto commesso da ciascun modello.\n",
        "- **MAPE (Mean Absolute Percentage Error)**: fornisce un’indicazione dell’errore medio in termini percentuali rispetto ai valori reali.\n",
        "- **MSLE (Mean Squared Logarithmic Error)**: utile nei casi in cui gli errori relativi siano più importanti degli assoluti, o in presenza di target con ordini di grandezza diversi.\n",
        "- **Explained Variance Score**: indica la proporzione della varianza spiegata dal modello (simile a $R^2$).\n",
        "- **Max Error**: evidenzia il peggior errore assoluto commesso su un'osservazione.\n",
        "- **Intervalli di Confidenza (CI95%)**: per le metriche `RMSE`, `MAE` e `MAPE` viene stimato un intervallo di confidenza al 95% tramite bootstrap resampling, al fine di rappresentare l'incertezza statistica associata alla metrica.\n",
        "\n",
        "Questa visualizzazione finale è utile per trarre conclusioni sulla bontà predittiva di ciascun modello e guidare la scelta del miglior approccio da adottare.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-29T20:38:15.404812Z",
          "iopub.status.busy": "2024-04-29T20:38:15.403803Z",
          "iopub.status.idle": "2024-04-29T20:38:15.421022Z",
          "shell.execute_reply": "2024-04-29T20:38:15.419432Z",
          "shell.execute_reply.started": "2024-04-29T20:38:15.404772Z"
        },
        "id": "5vxh_8pW9qkC"
      },
      "outputs": [],
      "source": [
        "def plot_estimator_scores(scores):\n",
        "    melted_r2 = scores[['model', 'r2_train', 'r2_test']]\n",
        "    melted_r2 = melted_r2.rename(columns={'r2_train':'train','r2_test':'test'})\n",
        "    melted_r2 = melted_r2.melt(id_vars='model', var_name='set', value_name='score')\n",
        "\n",
        "    fig, axs = plt.subplots(3, 3, figsize=(18, 14))\n",
        "    fig.tight_layout(pad=4)\n",
        "\n",
        "    sns.barplot(data=melted_r2, x='score', y='model', hue='set', ax=axs[0,0])\n",
        "    axs[0,0].set_title('R2 Score')\n",
        "    axs[0,0].legend(loc='lower right')\n",
        "\n",
        "    axs[0,1].set_title('RMSE ± CI95%')\n",
        "    for _, row in scores.iterrows():\n",
        "        axs[0,1].barh(row['model'], row['rmse'],\n",
        "                      xerr=[[row['rmse']-row['rmse_low']], [row['rmse_high']-row['rmse']]], capsize=5)\n",
        "\n",
        "    axs[0,2].set_title('MAE ± CI95%')\n",
        "    for _, row in scores.iterrows():\n",
        "        axs[0,2].barh(row['model'], row['mae'],\n",
        "                      xerr=[[row['mae']-row['mae_low']], [row['mae_high']-row['mae']]], capsize=5)\n",
        "\n",
        "    axs[1,0].set_title('MAPE ± CI95%')\n",
        "    for _, row in scores.iterrows():\n",
        "        axs[1,0].barh(row['model'], row['mape'],\n",
        "                      xerr=[[row['mape']-row['mape_low']], [row['mape_high']-row['mape']]], capsize=5)\n",
        "\n",
        "    axs[1,1].set_title('MSLE')\n",
        "    for _, row in scores.iterrows():\n",
        "        axs[1,1].barh(row['model'], row['msle'])\n",
        "\n",
        "    axs[1,2].set_title('Explained Variance')\n",
        "    for _, row in scores.iterrows():\n",
        "        axs[1,2].barh(row['model'], row['explained_var'])\n",
        "    axs[1,2].set_xlim(0,1)\n",
        "\n",
        "    axs[2,0].set_title('Max Error')\n",
        "    for _, row in scores.iterrows():\n",
        "        axs[2,0].barh(row['model'], row['max_error'])\n",
        "\n",
        "    axs[2,1].axis('off')\n",
        "    axs[2,2].axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-29T20:38:15.424047Z",
          "iopub.status.busy": "2024-04-29T20:38:15.422783Z",
          "iopub.status.idle": "2024-04-29T20:38:17.073862Z",
          "shell.execute_reply": "2024-04-29T20:38:17.072755Z",
          "shell.execute_reply.started": "2024-04-29T20:38:15.424005Z"
        },
        "id": "RTHU3LQ49qkD"
      },
      "outputs": [],
      "source": [
        "estimator_scores_df = pd.DataFrame(\n",
        "    all_scores,\n",
        "    columns = [\n",
        "        'model','r2_train','r2_test',\n",
        "        'rmse','rmse_low','rmse_high',\n",
        "        'mae','mae_low','mae_high',\n",
        "        'mape','mape_low','mape_high',\n",
        "        'msle','explained_var','max_error'\n",
        "    ]\n",
        ")\n",
        "plot_estimator_scores(estimator_scores_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vnXzcSTc2Z4u",
        "H_bIhHTRKAzQ",
        "xOMRnqcslVir",
        "YP2p8Z1ClVit",
        "tCa0HV05lVix",
        "CBNwKTBslViy",
        "Mcl2wO-FlVi0",
        "7CqjLtbdlVi0",
        "aXwTWsC2lVi3",
        "OSqJT3J-lVi4",
        "VFj50pJolVi4",
        "EOaI0YJZlVi4",
        "p4RNo3BclVi5",
        "bcj4BGSPlVi6",
        "sELWDyRclVi6",
        "rfO7GcablVi7",
        "sM7vW1UglVi8",
        "fY3JUaW7lVi9",
        "7xPxYN70lVi_",
        "uapeT7xKlVjA",
        "5uIugxCaMC9R"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}